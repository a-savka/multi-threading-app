# Отчёт по оптимизации производительности с использованием кэширования

## Цель задания

Целью данного задания было снижение нагрузки на источник данных и ускорение ответов сервиса путём применения двух подходов к кэшированию: локального (Caffeine) и распределённого (Redis).

## Инструменты

- **Язык и фреймворк:** Java 17, Spring Boot 3.5.5
- **Сборщик:** Maven
- **СУБД:** H2 (in-memory)
- **Кэш:** Caffeine, Redis
- **Контейнеризация:** Docker
- **Инструмент для замеров:** `curl`

## 1. Определение «горячих» данных

Анализ приложения показал, что наиболее частым и ресурсоёмким запросом является получение списка свободных слотов к врачу по определённой специальности. Этот запрос выполняется через эндпоинт `GET /api/slots/free` и обращается к методу `SlotService.getFreeSlotsBySpeciality(String speciality)`. Данные меняются только при бронировании слота, что делает их идеальным кандидатом для кэширования.

Для наглядной демонстрации разницы в производительности в метод `getFreeSlotsBySpeciality` была добавлена искусственная задержка в 1 секунду, имитирующая долгий запрос к базе данных.

```java
// в SlotService.java
@Cacheable(value = "slots", key = "#speciality")
public List<SlotDto> getFreeSlotsBySpeciality(String speciality) {
    // Имитация долгого запроса к базе данных
    try {
        Thread.sleep(1000); // 1 секунда
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
    return slotRepository.findByDoctorSpecialityAndStatus(speciality, "FREE").stream()
            .map(slotMapper::toDto)
            .collect(Collectors.toList());
}
```

При обновлении данных (бронировании слота) кэш необходимо инвалидировать. Это было реализовано в методе `reserveSlot` через `CacheManager`.

```java
// в SlotService.java
public void reserveSlot(Long slotId, Long patientId) {
    // ... логика бронирования
    slotRepository.save(slot);

    // Инвалидация кэша
    String speciality = slot.getDoctor().getSpeciality();
    cacheManager.getCache("slots").evict(speciality);
}
```

## 2. Вариант A: Локальный кэш (Caffeine)

### Конфигурация

1.  **pom.xml:** Добавлены зависимости `spring-boot-starter-cache` и `caffeine`.
2.  **Webinar2Application.java:** Добавлена аннотация `@EnableCaching`.
3.  **application.properties:**
    ```properties
    spring.cache.type=caffeine
    spring.cache.caffeine.spec=expireAfterWrite=10m
    ```

### Замеры производительности

Замеры проводились для специальности "Хирург".

| Действие                               | Время ответа | Результат      |
| -------------------------------------- | ------------ | -------------- |
| 1. Первый запрос (промах в кэш)        | ~1.26 с      | Cache Miss     |
| 2. Второй запрос (попадание в кэш)     | ~0.011 с     | **Cache Hit**  |
| 3. Бронирование слота (инвалидация)    | ~0.10 с      | Cache Eviction |
| 4. Запрос после инвалидации (промах)   | ~1.01 с      | Cache Miss     |

### Вывод по Caffeine

Caffeine показал превосходную эффективность, сократив время ответа более чем в 100 раз при попадании в кэш. Он прост в настройке и идеально подходит для монолитных приложений или сценариев, где не требуется согласованность кэша между несколькими экземплярами сервиса.

## 3. Вариант B: Распределённый кэш (Redis)

### Конфигурация

1.  **pom.xml:** Добавлена зависимость `spring-boot-starter-data-redis`.
2.  **application.properties:**
    ```properties
    spring.cache.type=redis
    ```
3.  **CacheConfig.java:** Для корректной работы распределённого кэша между несколькими инстансами был настроен `RedisCacheConfiguration` для использования JSON-сериализации. Без этого каждый инстанс использовал стандартную Java-сериализацию, что приводило к несовместимости кэша.

    ```java
    @Configuration
    public class CacheConfig {
        @Bean
        public RedisCacheConfiguration cacheConfiguration() {
            return RedisCacheConfiguration.defaultCacheConfig()
                    .entryTtl(Duration.ofMinutes(10))
                    .disableCachingNullValues()
                    .serializeValuesWith(SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer()));
        }
    }
    ```

### Замеры производительности (один экземпляр)

| Действие                               | Время ответа | Результат     |
| -------------------------------------- | ------------ | ------------- |
| 1. Первый запрос (промах в кэш)        | ~1.45 с      | Cache Miss    |
| 2. Второй запрос (попадание в кэш)     | ~0.008 с     | **Cache Hit** |

Производительность Redis на одном экземпляре сопоставима с Caffeine.

### Замеры производительности (два экземпляра)

Для проверки распределённой природы кэша были запущены два экземпляра приложения на портах 8081 и 8082.

1.  **Запрос на Instance 1 (port 8081) для специальности "Окулист"**:
    -   Время: **~1.45 с** (Cache Miss). Кэш для "Окулиста" был сохранён в Redis.
2.  **Запрос на Instance 2 (port 8082) для той же специальности "Окулист"**:
    -   Время: **~0.019 с** (**Cache Hit**).

### Вывод по Redis

Тест с двумя экземплярами наглядно демонстрирует главное преимущество Redis: **общий, распределённый кэш**. Второй экземпляр смог получить данные из кэша, который был заполнен первым экземпляром. Это критически важно для горизонтально масштабируемых приложений, так как обеспечивает консистентность данных и высокую производительность для всех пользователей, независимо от того, какой экземпляр сервиса обрабатывает их запрос.

## Итоговый вывод

Оба решения успешно справились с задачей кэширования, значительно ускорив повторные запросы.

-   **Caffeine** — отличное, простое и очень быстрое решение для локального кэширования в рамках одного экземпляра приложения.
-   **Redis** — является стандартом для распределённого кэширования в микросервисной или масштабируемой архитектуре. Несмотря на чуть более сложную первоначальную настройку (требуется Redis-сервер и конфигурация сериализации), он обеспечивает согласованность кэша между всеми экземплярами приложения, что является обязательным требованием для поддержания высокой производительности в распределённой среде.

Для проекта, который потенциально будет работать в нескольких экземплярах для обеспечения отказоустойчивости и высокой доступности, выбор **Redis** является стратегически верным решением.